import streamlit as st
import os
import json
import pandas as pd
import logging
import sys
from datetime import datetime
import time
from src.ui_elements.simple_nav import create_sidebar_navigation
import urllib.parse
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(
    page_title="AIè§†é¢‘å¤§å¸ˆ - è§†é¢‘åˆ†æ",
    page_icon="ğŸ¬",
    layout="wide"
)

# å¼ºåˆ¶æ³¨å…¥éšè—é¡¶æ æ ·å¼
st.markdown("""
<style>
/* éšè—streamlitè‡ªå¸¦å¯¼èˆªå’Œå…¶ä»–UIå…ƒç´  */
[data-testid="stSidebarNav"], 
header[data-testid="stHeader"],
div[data-testid="stToolbar"],
div[data-testid="stDecoration"],
div[data-testid="stStatusWidget"],
#MainMenu,
footer {
    display: none !important;
}
</style>
""", unsafe_allow_html=True)

# ç›´æ¥å¯¼å…¥å·¥å…·ç±»
try:
    from utils.analyzer import VideoAnalyzer
    from utils.processor import VideoProcessor
except ImportError as e:
    st.error(f"å¯¼å…¥å·¥å…·æ¨¡å—å¤±è´¥: {e}")
    # å¤‡ç”¨å¯¼å…¥æ–¹å¼
    import importlib.util
    
    def import_from_file(module_name, file_path):
        spec = importlib.util.spec_from_file_location(module_name, file_path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        return module
    
    try:
        analyzer_path = os.path.join(project_root, "utils", "analyzer.py")
        processor_path = os.path.join(project_root, "utils", "processor.py")
        
        analyzer_module = import_from_file("analyzer", analyzer_path)
        processor_module = import_from_file("processor", processor_path)
        
        VideoAnalyzer = analyzer_module.VideoAnalyzer
        VideoProcessor = processor_module.VideoProcessor
    except Exception as e:
        st.error(f"å¤‡ç”¨å¯¼å…¥æ–¹å¼ä¹Ÿå¤±è´¥: {e}")

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# æ–‡ä»¶è·¯å¾„
ANALYSIS_RESULTS_DIR = os.path.join('data', 'video_analysis', 'results')

from src.ui_elements.custom_theme import set_custom_theme
from src.config.settings import DIMENSIONS_DIR, INITIAL_DIMENSION_FILENAME

def get_available_templates():
    """è·å–data/dimensionsç›®å½•ä¸‹æ‰€æœ‰jsonæ¨¡æ¿æ–‡ä»¶å"""
    import glob
    template_files = glob.glob(os.path.join(DIMENSIONS_DIR, '*.json'))
    # æå–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºæ¨¡æ¿å
    template_names = [os.path.splitext(os.path.basename(f))[0] for f in template_files]
    return template_names

def load_dimension_template(template_name):
    """æ ¹æ®æ¨¡æ¿åç§°åŠ è½½ç»´åº¦æ¨¡æ¿æ–‡ä»¶"""
    file_path = os.path.join(DIMENSIONS_DIR, f"{template_name}.json")
    if os.path.exists(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                template_data = json.load(f)
                # æ£€æŸ¥æ˜¯å¦æ˜¯é¢„æœŸçš„æ ¼å¼
                if isinstance(template_data, dict) and len(template_data) > 0:
                    # å¦‚æœé¡¶å±‚åªæœ‰ä¸€ä¸ªé”®å€¼å¯¹ï¼Œå–ç¬¬ä¸€ä¸ªå€¼
                    if len(template_data) == 1:
                        dimensions = list(template_data.values())[0]
                        template_key = list(template_data.keys())[0]
                        logger.info(f"ä»æ–‡ä»¶åŠ è½½æ¨¡æ¿: {template_key}")
                        return dimensions
                    else:
                        # å¦‚æœç»“æ„ä¸æ˜¯é¢„æœŸçš„ï¼Œè¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„é¡¹
                        logger.warning(f"æ¨¡æ¿æ–‡ä»¶æ ¼å¼ä¸æ˜¯é¢„æœŸçš„å•é”®å€¼å¯¹: {template_name}")
                        for key, value in template_data.items():
                            if isinstance(value, dict) and 'level1' in value and 'level2' in value:
                                logger.info(f"ä½¿ç”¨æ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªæœ‰æ•ˆæ¨¡æ¿: {key}")
                                return value
                        logger.error(f"åœ¨æ¨¡æ¿ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç»´åº¦ç»“æ„: {template_name}")
                        return None
        except Exception as e:
            logger.error(f"åŠ è½½æ¨¡æ¿æ–‡ä»¶å‡ºé”™: {str(e)}")
    else:
        logger.warning(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    return None

def load_dimensions():
    """åŠ è½½å½“å‰ç»´åº¦ç»“æ„ï¼Œå¦‚æœsession_stateä¸­æ²¡æœ‰ï¼Œè‡ªåŠ¨åŠ è½½initial_dimensionæ¨¡æ¿"""
    if 'dimensions' in st.session_state:
        return st.session_state.dimensions
    else:
        # å°è¯•åŠ è½½åˆå§‹ç»´åº¦æ¨¡æ¿
        initial_template_path = os.path.join(DIMENSIONS_DIR, INITIAL_DIMENSION_FILENAME)
        if os.path.exists(initial_template_path):
            try:
                with open(initial_template_path, 'r', encoding='utf-8') as f:
                    template_data = json.load(f)
                    # è·å–æ¨¡æ¿çš„ç¬¬ä¸€ä¸ªå€¼ï¼Œå‡è®¾æ¨¡æ¿æ–‡ä»¶æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«å•ä¸ªé”®å€¼å¯¹
                    if isinstance(template_data, dict) and len(template_data) == 1:
                        dimensions = list(template_data.values())[0]
                        # å°†åŠ è½½çš„ç»´åº¦ä¿å­˜åˆ°session_state
                        st.session_state.dimensions = dimensions
                        logger.info(f"å·²è‡ªåŠ¨åŠ è½½åˆå§‹ç»´åº¦æ¨¡æ¿: {list(template_data.keys())[0]}")
                        return dimensions
            except Exception as e:
                logger.error(f"åŠ è½½åˆå§‹ç»´åº¦æ¨¡æ¿å¤±è´¥: {str(e)}")
        
        # å¦‚æœæ— æ³•åŠ è½½æ¨¡æ¿ï¼Œè¿”å›ç©ºç»´åº¦ç»“æ„
        empty_dimensions = {'title': "æœªå‘½å", 'level1': [], 'level2': {}}
        st.session_state.dimensions = empty_dimensions
        return empty_dimensions

def process_video_analysis(file, analysis_type, dimensions=None, keywords=None):
    """å¤„ç†è§†é¢‘åˆ†æ"""
    # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
    os.makedirs(ANALYSIS_RESULTS_DIR, exist_ok=True)
    
    try:
        # åˆå§‹åŒ–ç»“æœ
        results = {
            'type': analysis_type,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'matches': []
        }
        
        # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬å ä½
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # æç¤ºï¼šæ­£åœ¨å¤„ç†
        status_text.text("æ­£åœ¨å¤„ç†è§†é¢‘æ–‡ä»¶...")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç›´æ¥å¯è®¿é—®çš„è§†é¢‘URLæˆ–æœ¬åœ°æ–‡ä»¶
        is_url = file.startswith(('http://', 'https://'))
        
        if is_url:
            # æ˜¯URLï¼Œç›´æ¥ä¼ é€’ç»™å¤„ç†å™¨
            video_path = file
            status_text.text("æ­£åœ¨ä»URLè·å–è§†é¢‘...")
        else:
            # æ˜¯æœ¬åœ°æ–‡ä»¶ï¼Œè¯»å–å†…å®¹
            status_text.text("æ­£åœ¨å¤„ç†æœ¬åœ°è§†é¢‘æ–‡ä»¶...")
            video_path = file
        
        # æ›´æ–°è¿›åº¦åˆ°10%
        progress_bar.progress(0.1)
        
        # çƒ­è¯å¤„ç†ï¼šå¦‚æœæŒ‡å®šäº†å…³é”®è¯åˆ†æï¼Œè·å–çƒ­è¯è¡¨ID
        vocabulary_id = None
        if analysis_type == "å…³é”®è¯åˆ†æ" and keywords:
            # ä»src.core.hot_words_serviceå¯¼å…¥çƒ­è¯æœåŠ¡
            from src.core.hot_words_service import get_service
            hot_words_service = get_service()
            
            # å¯¼å…¥çƒ­è¯åˆ°é»˜è®¤åˆ†ç±»
            status_text.text("æ­£åœ¨ä¸Šä¼ å…³é”®è¯åˆ°äº‘ç«¯çƒ­è¯è¡¨...")
            
            # åˆ›å»ºä¸´æ—¶åˆ†ç±»åç§°
            temp_category = f"keyword_analysis_{datetime.now().strftime('%Y%m%d%H%M%S')}"
            
            # æ·»åŠ ä¸´æ—¶åˆ†ç±»
            hot_words_service.add_category(temp_category)
            
            # æ‰¹é‡æ·»åŠ å…³é”®è¯
            hot_words_service.batch_add_hotwords(temp_category, keywords)
            
            # ä¸Šä¼ çƒ­è¯è¡¨å¹¶è·å–vocabulary_id
            vocabulary_id = hot_words_service.get_vocabulary_id(temp_category)
            
            if vocabulary_id:
                status_text.text(f"å·²ä¸Šä¼ çƒ­è¯è¡¨: {len(keywords)} ä¸ªå…³é”®è¯")
            else:
                status_text.text("çƒ­è¯è¡¨ä¸Šä¼ å¤±è´¥ï¼Œå°†ä½¿ç”¨å¸¸è§„è¯†åˆ«")
        
        # æ›´æ–°è¿›åº¦åˆ°20%
        progress_bar.progress(0.2)
        
        # ä½¿ç”¨VideoProcessorå¤„ç†è§†é¢‘æˆ–ç›´æ¥è¯»å–CSV
        if video_path.lower().endswith('.csv'):
            # ç›´æ¥è¯»å–å·²å­˜åœ¨çš„å­—å¹•CSVï¼Œè·³è¿‡è§†é¢‘å¤„ç†
            status_text.text("æ£€æµ‹åˆ°CSVå­—å¹•æ–‡ä»¶ï¼Œç›´æ¥åŠ è½½æ–‡æœ¬...")
            try:
                df = pd.read_csv(video_path)
                status_text.text(f"å·²åŠ è½½å­—å¹•ï¼Œå…± {len(df)} æ¡è®°å½•")
            except Exception as e:
                status_text.error(f"è¯»å–CSVå¤±è´¥: {str(e)}")
                return None, None
        else:
            status_text.text("æ­£åœ¨ä½¿ç”¨è¯­éŸ³è¯†åˆ«å¤„ç†è§†é¢‘...")
            try:
                from utils.processor import VideoProcessor
                processor = VideoProcessor()
                output_csv = processor.process_video_file(video_path, vocabulary_id=vocabulary_id)
                if not output_csv or not os.path.exists(output_csv):
                    status_text.error("è§†é¢‘è¯­éŸ³è¯†åˆ«å¤„ç†å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œåç»­åˆ†æã€‚è¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚")
                    return None, None
                df = pd.read_csv(output_csv)
                status_text.text(f"è§†é¢‘å¤„ç†å®Œæˆï¼Œè¯†åˆ«äº† {len(df)} æ¡å¥å­")
            except ImportError:
                status_text.error("æ ¸å¿ƒå¤„ç†æ¨¡å—(VideoProcessor)å¯¼å…¥å¤±è´¥ï¼Œæ— æ³•å¤„ç†è§†é¢‘ã€‚")
                return None, None
        
        # æ›´æ–°è¿›åº¦åˆ°50%
        progress_bar.progress(0.5)
        
        # æ ¹æ®åˆ†æç±»å‹è¿›è¡Œåˆ†æ
        if analysis_type == "ç»´åº¦åˆ†æ":
            status_text.text("æ­£åœ¨è¿›è¡Œç»´åº¦åˆ†æ...")
            results['dimensions'] = dimensions
            
            # å¯¼å…¥VideoAnalyzerå¹¶åˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                from utils.analyzer import VideoAnalyzer
                analyzer = VideoAnalyzer()
                
                # åˆ†æç»´åº¦
                dimension_results = analyzer.analyze_dimensions(df, dimensions)
                
                # åˆå¹¶ç»“æœ
                if dimension_results and 'matches' in dimension_results:
                    results['matches'] = dimension_results['matches']
                else:
                    # åˆ†æå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹ŸåŒ¹é…
                    results['matches'] = _simulate_dimension_matching(df, dimensions)
            except ImportError:
                # VideoAnalyzerä¸å¯ç”¨ï¼Œä½¿ç”¨åŸæœ‰æ¨¡æ‹Ÿé€»è¾‘
                results['matches'] = _simulate_dimension_matching(df, dimensions)
            
        elif analysis_type == "å…³é”®è¯åˆ†æ":
            status_text.text("æ­£åœ¨è¿›è¡Œå…³é”®è¯åˆ†æ...")
            results['keywords'] = keywords
            
            # å¯¼å…¥VideoAnalyzerå¹¶åˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                from utils.analyzer import VideoAnalyzer
                analyzer = VideoAnalyzer()
                
                # åˆ†æå…³é”®è¯
                keyword_results = analyzer.analyze_keywords(df, keywords)
                
                # åˆå¹¶ç»“æœ
                if keyword_results and 'matches' in keyword_results:
                    results['matches'] = keyword_results['matches']
                else:
                    # åˆ†æå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹ŸåŒ¹é…
                    results['matches'] = _simulate_keyword_matching(df, keywords)
            except ImportError:
                # VideoAnalyzerä¸å¯ç”¨ï¼Œä½¿ç”¨åŸæœ‰æ¨¡æ‹Ÿé€»è¾‘
                results['matches'] = _simulate_keyword_matching(df, keywords)
        
        # æ›´æ–°è¿›åº¦åˆ°90%
        progress_bar.progress(0.9)
        
        # ä¿å­˜ç»“æœ
        result_file = os.path.join(ANALYSIS_RESULTS_DIR, f"analysis_{datetime.now().strftime('%Y%m%d%H%M%S')}.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # å®Œæˆå¤„ç†
        progress_bar.progress(1.0)
        status_text.text("åˆ†æå®Œæˆï¼")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ç»“æœ
        if len(results['matches']) == 1 and results['matches'][0].get('is_error', False):
            error_match = results['matches'][0]
            st.error(error_match['text'])
            st.info("åˆ†æå¤±è´¥ã€‚è¯·ç¡®ä¿æ‚¨çš„APIé…ç½®æ­£ç¡®ï¼Œå¹¶æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆã€‚æ‚¨å¯ä»¥å°è¯•ä½¿ç”¨ä¸åŒçš„è§†é¢‘æ–‡ä»¶æˆ–ç¨åå†è¯•ã€‚")
            return
        
        return results, result_file
    
    except Exception as e:
        logger.error(f"å¤„ç†è§†é¢‘åˆ†ææ—¶å‡ºé”™: {str(e)}")
        st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        return None, None

def _simulate_dimension_matching(df, dimensions):
    """
    æ¨¡æ‹Ÿç»´åº¦åŒ¹é…é€»è¾‘ï¼ˆå½“VideoAnalyzerä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
    
    å‚æ•°:
        df: è§†é¢‘æ–‡æœ¬æ•°æ®DataFrame
        dimensions: ç»´åº¦ç»“æ„
        
    è¿”å›:
        åŒ¹é…ç»“æœåˆ—è¡¨
    """
    matches = []
    
    # å¤„ç†æ¯æ¡è®°å½•
    for _, row in df.iterrows():
        text = row.get('text', '')
        if not text:
            continue
        
        # è·å–ä¸€çº§ç»´åº¦
        level1_dims = dimensions.get('level1', [])
        
        for dim1 in level1_dims:
            # æ¨¡æ‹ŸåŒ¹é…è®¡ç®—ï¼ŒåŸºäºç®€å•çš„å­—ç¬¦ä¸²åŒ…å«å…³ç³»
            contains_words = any(word in text for word in dim1.split())
            
            if contains_words:
                # æ¨¡æ‹ŸåŒ¹é…åˆ†æ•°
                score = 0.7 + np.random.random() * 0.3  # éšæœºç”Ÿæˆ0.7-1.0ä¹‹é—´çš„åˆ†æ•°
                
                # å°è¯•åŒ¹é…äºŒçº§ç»´åº¦
                level2_dims = dimensions.get('level2', {}).get(dim1, [])
                matched_l2 = None
                
                for dim2 in level2_dims:
                    contains_words_l2 = any(word in text for word in dim2.split())
                    
                    if contains_words_l2:
                        # æ‰¾åˆ°åŒ¹é…çš„äºŒçº§ç»´åº¦
                        matched_l2 = dim2
                        score = 0.7 + np.random.random() * 0.3  # æ›´æ–°åˆ†æ•°
                        break
                
                # æ·»åŠ åŒ¹é…ç»“æœ
                matches.append({
                    'dimension_level1': dim1,
                    'dimension_level2': matched_l2 if matched_l2 else '',
                    'timestamp': row.get('timestamp', '00:00:00'),
                    'text': text,
                    'score': float(score)  # ç¡®ä¿åˆ†æ•°æ˜¯floatç±»å‹
                })
    
    return matches

def _simulate_keyword_matching(df, keywords):
    """
    æ¨¡æ‹Ÿå…³é”®è¯åŒ¹é…é€»è¾‘ï¼ˆå½“VideoAnalyzerä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
    
    å‚æ•°:
        df: è§†é¢‘æ–‡æœ¬æ•°æ®DataFrame
        keywords: å…³é”®è¯åˆ—è¡¨
        
    è¿”å›:
        åŒ¹é…ç»“æœåˆ—è¡¨
    """
    matches = []
    
    # å¤„ç†æ¯æ¡è®°å½•
    for _, row in df.iterrows():
        text = row.get('text', '')
        if not text:
            continue
        
        # å¯¹æ¯ä¸ªå…³é”®è¯è¿›è¡ŒåŒ¹é…
        for keyword in keywords:
            # ç®€å•çš„åŒ…å«åŒ¹é…
            if keyword.lower() in text.lower():
                # æ¨¡æ‹ŸåŒ¹é…åˆ†æ•°
                score = 0.7 + np.random.random() * 0.3  # éšæœºç”Ÿæˆ0.7-1.0ä¹‹é—´çš„åˆ†æ•°
                
                # æ·»åŠ åŒ¹é…ç»“æœ
                matches.append({
                    'keyword': keyword,
                    'timestamp': row.get('timestamp', '00:00:00'),
                    'text': text,
                    'score': float(score)  # ç¡®ä¿åˆ†æ•°æ˜¯floatç±»å‹
                })
    
    return matches

def show_analysis_results(results, result_file):
    """æ˜¾ç¤ºåˆ†æç»“æœ"""
    if not results:
        return
    
    st.markdown("## åˆ†æç»“æœ")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ç»“æœ
    if len(results['matches']) == 1 and results['matches'][0].get('is_error', False):
        error_match = results['matches'][0]
        st.error(error_match['text'])
        st.info("åˆ†æå¤±è´¥ã€‚è¯·ç¡®ä¿æ‚¨çš„APIé…ç½®æ­£ç¡®ï¼Œå¹¶æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆã€‚æ‚¨å¯ä»¥å°è¯•ä½¿ç”¨ä¸åŒçš„è§†é¢‘æ–‡ä»¶æˆ–ç¨åå†è¯•ã€‚")
        return
    
    # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'video_info' in results:
        video_info = results['video_info']
        st.markdown(f"""
        **è§†é¢‘ä¿¡æ¯**:  
        - æ–‡ä»¶å: {video_info.get('file_name', 'æœªçŸ¥')}  
        - å¯¹è±¡å: {video_info.get('object', 'æœªçŸ¥')}
        """)
    
    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
    st.markdown(f"**åˆ†æç±»å‹**: {results['type']}")
    st.markdown(f"**åˆ†ææ—¶é—´**: {results['timestamp']}")
    st.markdown(f"**åŒ¹é…æ•°é‡**: {len(results['matches'])}")
    
    # ä¸‹è½½æŒ‰é’®
    with open(result_file, 'r', encoding='utf-8') as f:
        json_data = f.read()
        st.download_button(
            label="ä¸‹è½½åˆ†æç»“æœ (JSON)",
            data=json_data,
            file_name=os.path.basename(result_file),
            mime="application/json"
        )
    
    # æ˜¾ç¤ºåŒ¹é…ç»“æœ
    st.markdown("### åŒ¹é…è¯¦æƒ…")
    
    if results['type'] == "ç»´åº¦åˆ†æ":
        # åˆ›å»ºä¸€ä¸ªtab_idè®¡æ•°å™¨ï¼Œç¡®ä¿æ¯ä¸ªtabæœ‰å”¯ä¸€ID
        tab_id = 0
        
        # æŒ‰ç»´åº¦åˆ†ç»„æ˜¾ç¤º
        for dim1 in results.get('dimensions', {}).get('level1', []):
            # è¿‡æ»¤å‡ºå½“å‰ä¸€çº§ç»´åº¦çš„åŒ¹é…
            dim1_matches = [m for m in results['matches'] if m['dimension_level1'] == dim1]
            
            if dim1_matches:
                # ä½¿ç”¨expanderæ˜¾ç¤ºä¸€çº§ç»´åº¦
                with st.expander(f"{dim1} ({len(dim1_matches)}ä¸ªåŒ¹é…)", expanded=False):
                    # æŒ‰äºŒçº§ç»´åº¦åˆ†ç»„å¹¶ç›´æ¥æ˜¾ç¤ºå†…å®¹ï¼Œè€Œä¸æ˜¯å†ä½¿ç”¨åµŒå¥—çš„expander
                    for dim2 in results.get('dimensions', {}).get('level2', {}).get(dim1, []):
                        # è¿‡æ»¤å‡ºå½“å‰äºŒçº§ç»´åº¦çš„åŒ¹é…
                        dim2_matches = [m for m in dim1_matches if m['dimension_level2'] == dim2]
                        
                        if dim2_matches:
                            st.markdown(f"#### {dim2} ({len(dim2_matches)}ä¸ªåŒ¹é…)")
                            
                            # åˆ›å»ºä¸€ä¸ªå¯æŠ˜å åŒºåŸŸçš„æ›¿ä»£æ–¹æ¡ˆ - ä½¿ç”¨å®¹å™¨
                            dim2_container = st.container()
                            show_details = st.checkbox(f"æ˜¾ç¤ºè¯¦æƒ… - {dim2}", key=f"dim2_details_{tab_id}")
                            tab_id += 1
                            
                            if show_details:
                                with dim2_container:
                                    # æ˜¾ç¤ºæ¯ä¸ªåŒ¹é…
                                    for match in dim2_matches:
                                        st.markdown(f"""
                                        **æ—¶é—´ç‚¹**: {match['timestamp']}  
                                        **åŒ¹é…åˆ†æ•°**: {match['score']:.2f}  
                                        **æ–‡æœ¬**: {match['text']}  
                                        ---
                                        """)
    
    elif results['type'] == "å…³é”®è¯åˆ†æ":
        # æŒ‰å…³é”®è¯åˆ†ç»„æ˜¾ç¤º
        for keyword in results.get('keywords', []):
            # è¿‡æ»¤å‡ºå½“å‰å…³é”®è¯çš„åŒ¹é…
            keyword_matches = [m for m in results['matches'] if m['keyword'] == keyword]
            
            if keyword_matches:
                with st.expander(f"å…³é”®è¯: {keyword} ({len(keyword_matches)}ä¸ªåŒ¹é…)", expanded=False):
                    # æ˜¾ç¤ºæ¯ä¸ªåŒ¹é…
                    for match in keyword_matches:
                        st.markdown(f"""
                        **æ—¶é—´ç‚¹**: {match['timestamp']}  
                        **åŒ¹é…åˆ†æ•°**: {match['score']:.2f}  
                        **æ–‡æœ¬**: {match['text']}  
                        ---
                        """)

def show():
    """æ˜¾ç¤ºè§†é¢‘åˆ†æé¡µé¢"""
    # è®¾ç½®ä¸»é¢˜
    set_custom_theme()
    
    # åˆ›å»ºä¾§è¾¹æ å¯¼èˆª
    create_sidebar_navigation("è§†é¢‘åˆ†æ")
    
    # åŠ è½½ç»´åº¦ç»“æ„
    dimensions = load_dimensions()
    
    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ¬ è§†é¢‘åˆ†æ")
    st.write("ä¸Šä¼ è§†é¢‘æˆ–æä¾›è§†é¢‘é“¾æ¥ï¼Œè¿›è¡Œè¯­éŸ³å’Œå†…å®¹åˆ†æ")
    
    # ä¸Šä¼ è§†é¢‘éƒ¨åˆ†
    st.header("ä¸Šä¼ è§†é¢‘")
    
    # æ–¹å¼ä¸€ï¼šä¸Šä¼ æœ¬åœ°è§†é¢‘
    st.subheader("æ–¹å¼ä¸€ï¼šä¸Šä¼ æœ¬åœ°è§†é¢‘")
    uploaded_file = st.file_uploader("é€‰æ‹©è¦åˆ†æçš„è§†é¢‘æ–‡ä»¶", type=["mp4", "mov", "avi", "mkv"], help="æ”¯æŒå¸¸è§è§†é¢‘æ ¼å¼")
    
    if uploaded_file:
        # æ˜¾ç¤ºä¸Šä¼ çš„è§†é¢‘ä¿¡æ¯
        st.video(uploaded_file)
        st.info(f"æ–‡ä»¶å: {uploaded_file.name}, å¤§å°: {uploaded_file.size} å­—èŠ‚")
        
        # å°†ä¸Šä¼ çš„è§†é¢‘ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
        temp_video_path = os.path.join("data", "temp", uploaded_file.name)
        with open(temp_video_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        st.success(f"è§†é¢‘å·²ä¿å­˜åˆ°: {temp_video_path}")
        
        # ä¿å­˜è§†é¢‘è·¯å¾„åˆ°ä¼šè¯çŠ¶æ€
        st.session_state.video_path = temp_video_path
    
    # æ·»åŠ åˆ†éš”çº¿
    st.markdown("---")
    
    # åˆå§‹åŒ–OSSè§†é¢‘URLåˆ—è¡¨
    def _load_oss_video_urls():
        """ä»export_urls.csvåŠ è½½OSSè§†é¢‘URLåˆ—è¡¨"""
        csv_path = os.path.join("data", "input", "export_urls.csv")
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.m4v', '.webm', '.flv', '.wmv']
        
        if os.path.exists(csv_path):
            try:
                df = pd.read_csv(csv_path)
                if 'object' in df.columns and 'url' in df.columns:
                    # è¿‡æ»¤å‡ºè§†é¢‘æ–‡ä»¶
                    video_files = []
                    for _, row in df.iterrows():
                        obj_name = row['object']
                        url = row['url']
                        file_name = os.path.basename(urllib.parse.unquote(obj_name))
                        file_ext = os.path.splitext(file_name.lower())[1]
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶
                        if file_ext in video_extensions:
                            video_files.append({
                                'file_name': file_name,
                                'object': obj_name,
                                'url': url
                            })
                    
                    logger.info(f"ä»export_urls.csvæˆåŠŸåŠ è½½äº† {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
                    return video_files
                else:
                    logger.error("CSVæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œå¿…é¡»åŒ…å«'object'å’Œ'url'åˆ—")
            except Exception as e:
                logger.error(f"è¯»å–OSS URLåˆ—è¡¨å¤±è´¥: {str(e)}")
        else:
            logger.warning(f"OSS URLåˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        
        return []
    
    # åŠ è½½OSSè§†é¢‘
    if 'oss_videos' not in st.session_state:
        st.session_state.oss_videos = _load_oss_video_urls()
    
    # æ–¹å¼äºŒï¼šé˜¿é‡Œäº‘OSSè§†é¢‘
    st.subheader("æ–¹å¼äºŒï¼šé˜¿é‡Œäº‘OSSè§†é¢‘")
    
    # æ˜¾ç¤ºå¯é€‰æ‹©çš„è§†é¢‘æ–‡ä»¶
    if st.session_state.oss_videos:
        st.info(f"æ‰¾åˆ° {len(st.session_state.oss_videos)} ä¸ªOSSè§†é¢‘æ–‡ä»¶")
        
        # åˆ›å»ºé€‰æ‹©æ¡†
        selected_index = st.selectbox(
            "é€‰æ‹©è¦åˆ†æçš„OSSè§†é¢‘", 
            range(len(st.session_state.oss_videos)),
            format_func=lambda i: st.session_state.oss_videos[i]['file_name']
        )
        
        # æ˜¾ç¤ºé€‰ä¸­çš„è§†é¢‘ä¿¡æ¯
        selected_video = st.session_state.oss_videos[selected_index]
        st.markdown(f"""
        **é€‰ä¸­çš„è§†é¢‘**:  
        - æ–‡ä»¶å: {selected_video['file_name']}  
        - å¯¹è±¡å: {selected_video['object']}
        - URL: {selected_video['url']}
        """)
        
        # ä¿å­˜OSSè§†é¢‘ä¿¡æ¯åˆ°ä¼šè¯çŠ¶æ€
        st.session_state.oss_video = selected_video
        st.session_state.video_source = "oss"
    else:
        st.warning("æœªæ‰¾åˆ°å¯ç”¨çš„OSSè§†é¢‘ã€‚è¯·ç¡®è®¤data/input/export_urls.csvæ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®ã€‚")
        
        # ä¸Šä¼ è‡ªå®šä¹‰CSV
        st.markdown("### ä¸Šä¼ OSS URLåˆ—è¡¨")
        custom_csv = st.file_uploader("ä¸Šä¼ OSS URLåˆ—è¡¨", type=["csv"], help="å¿…é¡»åŒ…å«objectå’Œurlä¸¤åˆ—")
        if custom_csv:
            # ä¿å­˜ä¸Šä¼ çš„CSVæ–‡ä»¶
            os.makedirs(os.path.join("data", "input"), exist_ok=True)
            custom_csv_path = os.path.join("data", "input", "export_urls.csv")
            with open(custom_csv_path, "wb") as f:
                f.write(custom_csv.getbuffer())
            
            st.success(f"å·²ä¸Šä¼ OSS URLåˆ—è¡¨ï¼Œè¯·åˆ·æ–°é¡µé¢åŠ è½½URL")
            st.session_state.oss_videos = _load_oss_video_urls()
    
    # æ·»åŠ åˆ†éš”çº¿
    st.markdown("---")
    
    # åˆ†æè®¾ç½®éƒ¨åˆ† - ç›´æ¥æ˜¾ç¤ºåœ¨é¡µé¢ä¸Š
    st.header("åˆ†æè®¾ç½®")
    
    if 'video_path' not in st.session_state and 'oss_video' not in st.session_state and 'all_oss_videos' not in st.session_state:
        st.warning("è¯·å…ˆä¸Šä¼ è§†é¢‘æˆ–é€‰æ‹©OSSè§†é¢‘")
    else:
        # æ˜¾ç¤ºå½“å‰é€‰ä¸­çš„è§†é¢‘æº
        if 'video_source' in st.session_state:
            if st.session_state.video_source == "oss":
                st.info(f"å½“å‰åˆ†æOSSè§†é¢‘: {st.session_state.oss_video['file_name']}")
            elif st.session_state.video_source == "oss_batch":
                st.info(f"æ‰¹é‡åˆ†ææ¨¡å¼: å°†åˆ†æ {len(st.session_state.all_oss_videos)} ä¸ªOSSè§†é¢‘")
                # æ˜¾ç¤ºæ‰¹é‡åˆ†æçš„è§†é¢‘åˆ—è¡¨
                with st.expander("æŸ¥çœ‹å¾…åˆ†æçš„è§†é¢‘åˆ—è¡¨", expanded=False):
                    for i, video in enumerate(st.session_state.all_oss_videos):
                        st.write(f"{i+1}. {video['file_name']}")
        elif 'video_path' in st.session_state:
            st.info(f"å½“å‰åˆ†ææœ¬åœ°è§†é¢‘: {os.path.basename(st.session_state.video_path)}")
        
        # åˆ†æç±»å‹é€‰æ‹©
        if 'analysis_type' not in st.session_state:
            st.session_state.analysis_type = "ç»´åº¦åˆ†æ"  # é»˜è®¤å€¼
            
        analysis_type = st.radio(
            "é€‰æ‹©åˆ†æç±»å‹", 
            ["ç»´åº¦åˆ†æ", "å…³é”®è¯åˆ†æ"],
            key="analysis_type_radio",
            horizontal=True
        )
        
        # ä¿å­˜é€‰æ‹©åˆ°session_stateï¼Œä¾›å…¶ä»–åœ°æ–¹ä½¿ç”¨
        st.session_state.analysis_type = analysis_type
        
        if analysis_type == "ç»´åº¦åˆ†æ":
            # æ˜¾ç¤ºç»´åº¦é€‰æ‹©
            st.subheader("ç»´åº¦é€‰æ‹©")
            
            # æ·»åŠ æ¨¡æ¿é€‰æ‹©ä¸‹æ‹‰åˆ—è¡¨
            available_templates = get_available_templates()
            if available_templates:
                # ç¡®å®šé»˜è®¤é€‰æ‹©çš„æ¨¡æ¿
                default_index = 0
                initial_template_name = os.path.splitext(INITIAL_DIMENSION_FILENAME)[0]
                if initial_template_name in available_templates:
                    default_index = available_templates.index(initial_template_name)
                
                # åˆå§‹åŒ–session stateç”¨äºè·Ÿè¸ªå½“å‰é€‰ä¸­çš„æ¨¡æ¿
                if 'selected_template' not in st.session_state:
                    st.session_state.selected_template = available_templates[default_index]
                
                # å¤„ç†æ¨¡æ¿å˜æ›´çš„å›è°ƒå‡½æ•°
                def on_template_change():
                    new_template = st.session_state.dimension_template_selector
                    # åªæœ‰å½“æ¨¡æ¿çœŸæ­£å˜åŒ–æ—¶æ‰åŠ è½½
                    if new_template != st.session_state.selected_template:
                        st.session_state.selected_template = new_template
                        dimensions = load_dimension_template(new_template)
                        if dimensions:
                            st.session_state.dimensions = dimensions
                            # ä¸è¦ä½¿ç”¨st.successï¼Œå› ä¸ºåœ¨å›è°ƒä¸­å®ƒä¼šè¢«ä¸‹ä¸€ä¸ªé‡æ¸²æŸ“è¦†ç›–
                            # æ”¹ä¸ºä½¿ç”¨session stateè®°å½•åŠ è½½æˆåŠŸä¿¡æ¯ï¼Œåœ¨ä¸‹æ¬¡æ¸²æŸ“æ—¶æ˜¾ç¤º
                            st.session_state.template_load_success = f"å·²åŠ è½½æ¨¡æ¿: {new_template}"
                        else:
                            st.session_state.template_load_error = f"åŠ è½½æ¨¡æ¿å¤±è´¥: {new_template}"
                
                # ä½¿ç”¨é€‰æ‹©æ¡†è®©ç”¨æˆ·é€‰æ‹©æ¨¡æ¿ï¼Œå¹¶è®¾ç½®å›è°ƒå‡½æ•°
                selected_template = st.selectbox(
                    "é€‰æ‹©ç»´åº¦æ¨¡æ¿",
                    available_templates,
                    index=default_index,
                    key="dimension_template_selector",
                    help="ä»data/dimensionsæ–‡ä»¶å¤¹åŠ è½½æ¨¡æ¿",
                    on_change=on_template_change
                )
                
                # æ˜¾ç¤ºåŠ è½½æˆåŠŸæˆ–å¤±è´¥çš„æ¶ˆæ¯
                if 'template_load_success' in st.session_state:
                    st.success(st.session_state.template_load_success)
                    # æ˜¾ç¤ºåæ¸…é™¤ï¼Œé¿å…é‡å¤æ˜¾ç¤º
                    del st.session_state.template_load_success
                
                if 'template_load_error' in st.session_state:
                    st.error(st.session_state.template_load_error)
                    # æ˜¾ç¤ºåæ¸…é™¤ï¼Œé¿å…é‡å¤æ˜¾ç¤º
                    del st.session_state.template_load_error
            
            # åŠ è½½å½“å‰ç»´åº¦ç»“æ„
            dimensions = load_dimensions()
            
            if not dimensions or not dimensions.get('level1'):
                st.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ†æç»´åº¦ã€‚è¯·å‰å¾€ç»´åº¦ç®¡ç†é¡µé¢åˆ›å»ºæˆ–åŠ è½½ç»´åº¦æ¨¡æ¿ã€‚")
            else:
                st.markdown(f"**å½“å‰åŠ è½½çš„ç»´åº¦æ¨¡æ¿**: {dimensions.get('title', 'æœªå‘½å')}")
                
                # æ˜¾ç¤ºç»´åº¦åˆ—è¡¨
                for dim1 in dimensions.get('level1', []):
                    with st.expander(f"{dim1}", expanded=False):
                        # æ˜¾ç¤ºäºŒçº§ç»´åº¦
                        dim2_list = dimensions.get('level2', {}).get(dim1, [])
                        if dim2_list:
                            st.markdown(", ".join(dim2_list))
                        else:
                            st.markdown("*æ— äºŒçº§ç»´åº¦*")
                
                # ç‚¹å‡»åˆ†ææŒ‰é’®
                if st.button("å¼€å§‹ç»´åº¦åˆ†æ", key="dim_analysis_btn"):
                    # ç¡®å®šè§†é¢‘æ¥æº
                    video_source = st.session_state.get('video_source', 'local')
                    
                    # æ‰¹é‡åˆ†ææ¨¡å¼
                    if video_source == "oss_batch":
                        all_videos = st.session_state.all_oss_videos
                        st.info(f"å¼€å§‹æ‰¹é‡åˆ†æ {len(all_videos)} ä¸ªOSSè§†é¢‘...")
                        
                        # åˆ›å»ºè¿›åº¦æ¡æ˜¾ç¤ºæ€»ä½“è¿›åº¦
                        batch_progress = st.progress(0)
                        batch_status = st.empty()
                        
                        # åˆ›å»ºç»“æœå®¹å™¨
                        all_results = []
                        
                        # å¤„ç†æ¯ä¸ªè§†é¢‘
                        for i, video in enumerate(all_videos):
                            try:
                                # æ›´æ–°è¿›åº¦
                                progress_pct = i / len(all_videos)
                                batch_progress.progress(progress_pct)
                                batch_status.info(f"æ­£åœ¨å¤„ç† ({i+1}/{len(all_videos)}): {video['file_name']}")
                                
                                # è¿™é‡Œåº”è¯¥æœ‰å®é™…çš„è§†é¢‘å¤„ç†é€»è¾‘
                                # ç°åœ¨æˆ‘ä»¬åªæ˜¯æ¨¡æ‹Ÿä¸€ä¸ªCSVæ–‡ä»¶ä½œä¸ºè¾“å…¥
                                sample_data_path = os.path.join("data", "temp", "sample_subtitles.csv")
                                
                                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ ·æœ¬æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
                                if not os.path.exists(sample_data_path):
                                    # åˆ›å»ºç›®å½•
                                    os.makedirs(os.path.dirname(sample_data_path), exist_ok=True)
                                    
                                    # åˆ›å»ºæ ·æœ¬æ•°æ®
                                    sample_data = pd.DataFrame({
                                        'timestamp': ['00:00:10', '00:00:20', '00:00:30', '00:00:40', '00:00:50'],
                                        'text': [
                                            'å“ç‰Œçš„å½±å“åŠ›æ­£åœ¨ä¸æ–­å¢é•¿',
                                            'æˆ‘ä»¬éœ€è¦æé«˜ç”¨æˆ·çš„å“ç‰Œè®¤çŸ¥åº¦',
                                            'ç”¨æˆ·ä½“éªŒæ˜¯æˆ‘ä»¬äº§å“çš„æ ¸å¿ƒç«äº‰åŠ›',
                                            'åˆ›æ–°æ˜¯æ¨åŠ¨å“ç‰Œå‘å‰å‘å±•çš„å…³é”®',
                                            'æˆ‘ä»¬çš„äº§å“è´¨é‡å¾—åˆ°äº†ç”¨æˆ·çš„é«˜åº¦è®¤å¯'
                                        ]
                                    })
                                    sample_data.to_csv(sample_data_path, index=False)
                                
                                # å¤„ç†åˆ†æ
                                results, result_file = process_video_analysis(sample_data_path, "ç»´åº¦åˆ†æ", dimensions)
                                
                                if results:
                                    # æ·»åŠ è§†é¢‘ä¿¡æ¯åˆ°ç»“æœ
                                    results['video_info'] = {
                                        'file_name': video['file_name'],
                                        'object': video['object'],
                                        'url': video['url']
                                    }
                                    all_results.append((results, result_file))
                            except Exception as e:
                                st.error(f"å¤„ç†è§†é¢‘ {video['file_name']} æ—¶å‡ºé”™: {str(e)}")
                        
                        # æ›´æ–°è¿›åº¦ä¸ºå®Œæˆ
                        batch_progress.progress(1.0)
                        batch_status.success(f"æ‰¹é‡åˆ†æå®Œæˆï¼ŒæˆåŠŸå¤„ç† {len(all_results)}/{len(all_videos)} ä¸ªè§†é¢‘")
                        
                        # æ˜¾ç¤ºæ‰¹é‡åˆ†æç»“æœ
                        if all_results:
                            st.subheader(f"æ‰¹é‡åˆ†æç»“æœ ({len(all_results)} ä¸ªè§†é¢‘)")
                            
                            # ä¸ºæ¯ä¸ªè§†é¢‘åˆ›å»ºä¸€ä¸ªå±•å¼€åŒºåŸŸæ˜¾ç¤ºç»“æœ
                            for i, (results, result_file) in enumerate(all_results):
                                video_name = results['video_info']['file_name']
                                with st.expander(f"{i+1}. {video_name}", expanded=i==0):
                                    # ä¸ä½¿ç”¨show_analysis_resultsé¿å…åµŒå¥—expander
                                    st.markdown("## åˆ†æç»“æœ")
                                    
                                    # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
                                    video_info = results['video_info']
                                    st.markdown(f"""
                                    **è§†é¢‘ä¿¡æ¯**:  
                                    - æ–‡ä»¶å: {video_info.get('file_name', 'æœªçŸ¥')}  
                                    - å¯¹è±¡å: {video_info.get('object', 'æœªçŸ¥')}
                                    """)
                                    
                                    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                                    st.markdown(f"**åˆ†æç±»å‹**: {results['type']}")
                                    st.markdown(f"**åˆ†ææ—¶é—´**: {results['timestamp']}")
                                    st.markdown(f"**åŒ¹é…æ•°é‡**: {len(results['matches'])}")
                                    
                                    # ä¸‹è½½æŒ‰é’®
                                    with open(result_file, 'r', encoding='utf-8') as f:
                                        json_data = f.read()
                                        st.download_button(
                                            label="ä¸‹è½½åˆ†æç»“æœ (JSON)",
                                            data=json_data,
                                            file_name=os.path.basename(result_file),
                                            mime="application/json"
                                        )
                                    
                                    # æ˜¾ç¤ºåŒ¹é…ç»“æœ
                                    st.markdown("### åŒ¹é…è¯¦æƒ…")
                                    
                                    # æ ¹æ®åˆ†æç±»å‹æ˜¾ç¤ºä¸åŒçš„ç»“æœï¼ˆç›´æ¥æ˜¾ç¤ºï¼Œä¸ä½¿ç”¨åµŒå¥—expanderï¼‰
                                    if results['type'] == "ç»´åº¦åˆ†æ":
                                        # ç›´æ¥æ˜¾ç¤ºæ‰€æœ‰ç»´åº¦åŒ¹é…ï¼Œä¸ä½¿ç”¨expander
                                        for dim1 in results.get('dimensions', {}).get('level1', []):
                                            # è¿‡æ»¤å‡ºå½“å‰ä¸€çº§ç»´åº¦çš„åŒ¹é…
                                            dim1_matches = [m for m in results['matches'] if m['dimension_level1'] == dim1]
                                            
                                            if dim1_matches:
                                                st.markdown(f"#### {dim1} ({len(dim1_matches)}ä¸ªåŒ¹é…)")
                                                
                                                # æŒ‰äºŒçº§ç»´åº¦åˆ†ç»„
                                                for dim2 in results.get('dimensions', {}).get('level2', {}).get(dim1, []):
                                                    # è¿‡æ»¤å‡ºå½“å‰äºŒçº§ç»´åº¦çš„åŒ¹é…
                                                    dim2_matches = [m for m in dim1_matches if m['dimension_level2'] == dim2]
                                                    
                                                    if dim2_matches:
                                                        st.markdown(f"##### {dim2} ({len(dim2_matches)}ä¸ªåŒ¹é…)")
                                                        
                                                        # æ˜¾ç¤ºæ¯ä¸ªåŒ¹é…
                                                        for match in dim2_matches:
                                                            st.markdown(f"""
                                                            **æ—¶é—´ç‚¹**: {match['timestamp']}  
                                                            **åŒ¹é…åˆ†æ•°**: {match['score']:.2f}  
                                                            **æ–‡æœ¬**: {match['text']}  
                                                            ---
                                                            """)
                                    
                                    elif results['type'] == "å…³é”®è¯åˆ†æ":
                                        # ç›´æ¥æ˜¾ç¤ºæ‰€æœ‰å…³é”®è¯åŒ¹é…ï¼Œä¸ä½¿ç”¨expander
                                        for keyword in results.get('keywords', []):
                                            # è¿‡æ»¤å‡ºå½“å‰å…³é”®è¯çš„åŒ¹é…
                                            keyword_matches = [m for m in results['matches'] if m['keyword'] == keyword]
                                            
                                            if keyword_matches:
                                                st.markdown(f"#### å…³é”®è¯: {keyword} ({len(keyword_matches)}ä¸ªåŒ¹é…)")
                                                
                                                # æ˜¾ç¤ºæ¯ä¸ªåŒ¹é…
                                                for match in keyword_matches:
                                                    st.markdown(f"""
                                                    **æ—¶é—´ç‚¹**: {match['timestamp']}  
                                                    **åŒ¹é…åˆ†æ•°**: {match['score']:.2f}  
                                                    **æ–‡æœ¬**: {match['text']}  
                                                    ---
                                                    """)
                    else:
                        # å•ä¸ªè§†é¢‘åˆ†ææ¨¡å¼
                        with st.spinner("æ­£åœ¨å¤„ç†è§†é¢‘åˆ†æ..."):
                            video_source = st.session_state.get('video_source', 'local')
                            video_path = ""
                            
                            if video_source == "oss":
                                oss_video = st.session_state.oss_video
                                st.info(f"æ­£åœ¨åˆ†æOSSè§†é¢‘: {oss_video['file_name']}")
                                
                                # ç›´æ¥ä½¿ç”¨OSS URLè¿›è¡Œå¤„ç†ï¼Œé¿å…ä¸‹è½½
                                video_path = oss_video['url']
                                st.write(f"è§†é¢‘URL: {video_path}")
                            else:
                                video_path = st.session_state.get('video_path', '')
                                if video_path:
                                    st.info(f"æ­£åœ¨åˆ†ææœ¬åœ°è§†é¢‘: {os.path.basename(video_path)}")
                                else:
                                    st.error("æœªé€‰æ‹©ä»»ä½•è§†é¢‘æ–‡ä»¶")
                                    return
                            
                            # å¦‚æœCSVæ–‡ä»¶å­˜åœ¨ä¸”åœ¨æµ‹è¯•æ¨¡å¼ï¼Œåˆ™ä½¿ç”¨å®ƒ
                            if 'use_sample' in st.session_state and st.session_state.use_sample:
                                sample_data_path = os.path.join("data", "temp", "sample_subtitles.csv")
                                if os.path.exists(sample_data_path):
                                    st.info("ä½¿ç”¨ç¤ºä¾‹å­—å¹•æ•°æ®è¿›è¡Œåˆ†æ")
                                    video_path = sample_data_path
                            
                            # å¦‚æœæ²¡æœ‰è§†é¢‘è·¯å¾„ï¼Œå°è¯•ä½¿ç”¨ç¤ºä¾‹
                            if not video_path:
                                st.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘è·¯å¾„")
                                return
                            
                            # å¤„ç†åˆ†æ
                            results, result_file = process_video_analysis(video_path, "ç»´åº¦åˆ†æ", dimensions)
                            
                            # æ˜¾ç¤ºç»“æœ
                            if results:
                                show_analysis_results(results, result_file)
            
        elif analysis_type == "å…³é”®è¯åˆ†æ":
            # æ˜¾ç¤ºå…³é”®è¯è¾“å…¥
            st.subheader("å…³é”®è¯è®¾ç½®")
            keywords_input = st.text_area("è¾“å…¥å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", height=150)
            
            if keywords_input.strip():
                # å¤„ç†å…³é”®è¯
                keywords = [kw.strip() for kw in keywords_input.split('\n') if kw.strip()]
                st.markdown(f"å·²è¾“å…¥ {len(keywords)} ä¸ªå…³é”®è¯")
                
                # ç‚¹å‡»åˆ†ææŒ‰é’®
                if st.button("å¼€å§‹å…³é”®è¯åˆ†æ", key="kw_analysis_btn"):
                    # ç¡®å®šè§†é¢‘æ¥æº
                    video_source = st.session_state.get('video_source', 'local')
                    
                    # æ‰¹é‡åˆ†ææ¨¡å¼
                    if video_source == "oss_batch":
                        all_videos = st.session_state.all_oss_videos
                        st.info(f"å¼€å§‹æ‰¹é‡å…³é”®è¯åˆ†æ {len(all_videos)} ä¸ªOSSè§†é¢‘...")
                        
                        # åˆ›å»ºè¿›åº¦æ¡æ˜¾ç¤ºæ€»ä½“è¿›åº¦
                        batch_progress = st.progress(0)
                        batch_status = st.empty()
                        
                        # åˆ›å»ºç»“æœå®¹å™¨
                        all_results = []
                        
                        # å¤„ç†æ¯ä¸ªè§†é¢‘
                        for i, video in enumerate(all_videos):
                            try:
                                # æ›´æ–°è¿›åº¦
                                progress_pct = i / len(all_videos)
                                batch_progress.progress(progress_pct)
                                batch_status.info(f"æ­£åœ¨å¤„ç† ({i+1}/{len(all_videos)}): {video['file_name']}")
                                
                                # è¿™é‡Œåº”è¯¥æœ‰å®é™…çš„è§†é¢‘å¤„ç†é€»è¾‘
                                # ç°åœ¨æˆ‘ä»¬åªæ˜¯æ¨¡æ‹Ÿä¸€ä¸ªCSVæ–‡ä»¶ä½œä¸ºè¾“å…¥
                                sample_data_path = os.path.join("data", "temp", "sample_subtitles.csv")
                                
                                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ ·æœ¬æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
                                if not os.path.exists(sample_data_path):
                                    # åˆ›å»ºç›®å½•
                                    os.makedirs(os.path.dirname(sample_data_path), exist_ok=True)
                                    
                                    # åˆ›å»ºæ ·æœ¬æ•°æ®
                                    sample_data = pd.DataFrame({
                                        'timestamp': ['00:00:10', '00:00:20', '00:00:30', '00:00:40', '00:00:50'],
                                        'text': [
                                            'å“ç‰Œçš„å½±å“åŠ›æ­£åœ¨ä¸æ–­å¢é•¿',
                                            'æˆ‘ä»¬éœ€è¦æé«˜ç”¨æˆ·çš„å“ç‰Œè®¤çŸ¥åº¦',
                                            'ç”¨æˆ·ä½“éªŒæ˜¯æˆ‘ä»¬äº§å“çš„æ ¸å¿ƒç«äº‰åŠ›',
                                            'åˆ›æ–°æ˜¯æ¨åŠ¨å“ç‰Œå‘å‰å‘å±•çš„å…³é”®',
                                            'æˆ‘ä»¬çš„äº§å“è´¨é‡å¾—åˆ°äº†ç”¨æˆ·çš„é«˜åº¦è®¤å¯'
                                        ]
                                    })
                                    sample_data.to_csv(sample_data_path, index=False)
                                
                                # å¤„ç†åˆ†æ
                                results, result_file = process_video_analysis(sample_data_path, "å…³é”®è¯åˆ†æ", keywords=keywords)
                                
                                if results:
                                    # æ·»åŠ è§†é¢‘ä¿¡æ¯åˆ°ç»“æœ
                                    results['video_info'] = {
                                        'file_name': video['file_name'],
                                        'object': video['object'],
                                        'url': video['url']
                                    }
                                    all_results.append((results, result_file))
                            except Exception as e:
                                st.error(f"å¤„ç†è§†é¢‘ {video['file_name']} æ—¶å‡ºé”™: {str(e)}")
                        
                        # æ›´æ–°è¿›åº¦ä¸ºå®Œæˆ
                        batch_progress.progress(1.0)
                        batch_status.success(f"æ‰¹é‡åˆ†æå®Œæˆï¼ŒæˆåŠŸå¤„ç† {len(all_results)}/{len(all_videos)} ä¸ªè§†é¢‘")
                        
                        # æ˜¾ç¤ºæ‰¹é‡åˆ†æç»“æœ
                        if all_results:
                            st.subheader(f"æ‰¹é‡å…³é”®è¯åˆ†æç»“æœ ({len(all_results)} ä¸ªè§†é¢‘)")
                            
                            # ä¸ºæ¯ä¸ªè§†é¢‘åˆ›å»ºä¸€ä¸ªå±•å¼€åŒºåŸŸæ˜¾ç¤ºç»“æœ
                            for i, (results, result_file) in enumerate(all_results):
                                video_name = results['video_info']['file_name']
                                with st.expander(f"{i+1}. {video_name}", expanded=i==0):
                                    # ä¸ä½¿ç”¨show_analysis_resultsé¿å…åµŒå¥—expander
                                    st.markdown("## åˆ†æç»“æœ")
                                    
                                    # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
                                    video_info = results['video_info']
                                    st.markdown(f"""
                                    **è§†é¢‘ä¿¡æ¯**:  
                                    - æ–‡ä»¶å: {video_info.get('file_name', 'æœªçŸ¥')}  
                                    - å¯¹è±¡å: {video_info.get('object', 'æœªçŸ¥')}
                                    """)
                                    
                                    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                                    st.markdown(f"**åˆ†æç±»å‹**: {results['type']}")
                                    st.markdown(f"**åˆ†ææ—¶é—´**: {results['timestamp']}")
                                    st.markdown(f"**åŒ¹é…æ•°é‡**: {len(results['matches'])}")
                                    
                                    # ä¸‹è½½æŒ‰é’®
                                    with open(result_file, 'r', encoding='utf-8') as f:
                                        json_data = f.read()
                                        st.download_button(
                                            label="ä¸‹è½½åˆ†æç»“æœ (JSON)",
                                            data=json_data,
                                            file_name=os.path.basename(result_file),
                                            mime="application/json"
                                        )
                                    
                                    # æ˜¾ç¤ºåŒ¹é…ç»“æœ
                                    st.markdown("### åŒ¹é…è¯¦æƒ…")
                                    
                                    # æ ¹æ®åˆ†æç±»å‹æ˜¾ç¤ºä¸åŒçš„ç»“æœï¼ˆç›´æ¥æ˜¾ç¤ºï¼Œä¸ä½¿ç”¨åµŒå¥—expanderï¼‰
                                    if results['type'] == "ç»´åº¦åˆ†æ":
                                        # ç›´æ¥æ˜¾ç¤ºæ‰€æœ‰ç»´åº¦åŒ¹é…ï¼Œä¸ä½¿ç”¨expander
                                        for dim1 in results.get('dimensions', {}).get('level1', []):
                                            # è¿‡æ»¤å‡ºå½“å‰ä¸€çº§ç»´åº¦çš„åŒ¹é…
                                            dim1_matches = [m for m in results['matches'] if m['dimension_level1'] == dim1]
                                            
                                            if dim1_matches:
                                                st.markdown(f"#### {dim1} ({len(dim1_matches)}ä¸ªåŒ¹é…)")
                                                
                                                # æŒ‰äºŒçº§ç»´åº¦åˆ†ç»„
                                                for dim2 in results.get('dimensions', {}).get('level2', {}).get(dim1, []):
                                                    # è¿‡æ»¤å‡ºå½“å‰äºŒçº§ç»´åº¦çš„åŒ¹é…
                                                    dim2_matches = [m for m in dim1_matches if m['dimension_level2'] == dim2]
                                                    
                                                    if dim2_matches:
                                                        st.markdown(f"##### {dim2} ({len(dim2_matches)}ä¸ªåŒ¹é…)")
                                                        
                                                        # æ˜¾ç¤ºæ¯ä¸ªåŒ¹é…
                                                        for match in dim2_matches:
                                                            st.markdown(f"""
                                                            **æ—¶é—´ç‚¹**: {match['timestamp']}  
                                                            **åŒ¹é…åˆ†æ•°**: {match['score']:.2f}  
                                                            **æ–‡æœ¬**: {match['text']}  
                                                            ---
                                                            """)
                                    
                                    elif results['type'] == "å…³é”®è¯åˆ†æ":
                                        # ç›´æ¥æ˜¾ç¤ºæ‰€æœ‰å…³é”®è¯åŒ¹é…ï¼Œä¸ä½¿ç”¨expander
                                        for keyword in results.get('keywords', []):
                                            # è¿‡æ»¤å‡ºå½“å‰å…³é”®è¯çš„åŒ¹é…
                                            keyword_matches = [m for m in results['matches'] if m['keyword'] == keyword]
                                            
                                            if keyword_matches:
                                                st.markdown(f"#### å…³é”®è¯: {keyword} ({len(keyword_matches)}ä¸ªåŒ¹é…)")
                                                
                                                # æ˜¾ç¤ºæ¯ä¸ªåŒ¹é…
                                                for match in keyword_matches:
                                                    st.markdown(f"""
                                                    **æ—¶é—´ç‚¹**: {match['timestamp']}  
                                                    **åŒ¹é…åˆ†æ•°**: {match['score']:.2f}  
                                                    **æ–‡æœ¬**: {match['text']}  
                                                    ---
                                                    """)
                    else:
                        # å•ä¸ªè§†é¢‘åˆ†ææ¨¡å¼
                        with st.spinner("æ­£åœ¨å¤„ç†è§†é¢‘åˆ†æ..."):
                            video_source = st.session_state.get('video_source', 'local')
                            video_path = ""
                            
                            if video_source == "oss":
                                oss_video = st.session_state.oss_video
                                st.info(f"æ­£åœ¨åˆ†æOSSè§†é¢‘: {oss_video['file_name']}")
                                
                                # ç›´æ¥ä½¿ç”¨OSS URLè¿›è¡Œå¤„ç†ï¼Œé¿å…ä¸‹è½½
                                video_path = oss_video['url']
                                st.write(f"è§†é¢‘URL: {video_path}")
                            else:
                                video_path = st.session_state.get('video_path', '')
                                if video_path:
                                    st.info(f"æ­£åœ¨åˆ†ææœ¬åœ°è§†é¢‘: {os.path.basename(video_path)}")
                                else:
                                    st.error("æœªé€‰æ‹©ä»»ä½•è§†é¢‘æ–‡ä»¶")
                                    return
                            
                            # å¦‚æœCSVæ–‡ä»¶å­˜åœ¨ä¸”åœ¨æµ‹è¯•æ¨¡å¼ï¼Œåˆ™ä½¿ç”¨å®ƒ
                            if 'use_sample' in st.session_state and st.session_state.use_sample:
                                sample_data_path = os.path.join("data", "temp", "sample_subtitles.csv")
                                if os.path.exists(sample_data_path):
                                    st.info("ä½¿ç”¨ç¤ºä¾‹å­—å¹•æ•°æ®è¿›è¡Œåˆ†æ")
                                    video_path = sample_data_path
                            
                            # å¦‚æœæ²¡æœ‰è§†é¢‘è·¯å¾„ï¼Œå°è¯•ä½¿ç”¨ç¤ºä¾‹
                            if not video_path:
                                st.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„è§†é¢‘è·¯å¾„")
                                return
                            
                            # å¤„ç†åˆ†æ
                            results, result_file = process_video_analysis(video_path, "å…³é”®è¯åˆ†æ", keywords=keywords)
                            
                            # æ˜¾ç¤ºç»“æœ
                            if results:
                                show_analysis_results(results, result_file)
                else:
                    st.warning("è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªå…³é”®è¯")

if __name__ == "__main__":
    show() 